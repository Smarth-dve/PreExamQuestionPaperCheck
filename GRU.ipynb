{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas tqdm sklearn tensorflow keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU,SimpleRNN\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib inline\n",
    "from plotly import graph_objs as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      Sr No.                                          Questions  \\\n",
       "0         1  Given is an array after the first partition of...   \n",
       "1         2  How many steps are required to solve Tower of ...   \n",
       "2         3  How many comparisons are required to find elem...   \n",
       "3         4  Given an array A[-3:4, 6:10], Find the address...   \n",
       "4         5  Consider the following list of 10 numbers: 35,...   \n",
       "..      ...                                                ...   \n",
       "149     150  Give the difference between: (i) Tree and Grap...   \n",
       "150     151  What is meant by collision resolution techniqu...   \n",
       "151     152  Comment whether the graph is connected or not ...   \n",
       "152     153  What is an AVL tree? Perform following operati...   \n",
       "153     154  Insert the given numbers in binary search tree...   \n",
       "\n",
       "           BloomsTaxClass          Keyword  \n",
       "0                remember            which  \n",
       "1                remember              how  \n",
       "2                remember              how  \n",
       "3                remember             find  \n",
       "4        apply , remember      show , what  \n",
       "..                    ...              ...  \n",
       "149            understand       difference  \n",
       "150  remember, understand    what, explain  \n",
       "151               analyze          comment  \n",
       "152       remember, apply    what, perform  \n",
       "153                 apply  insert, mention  \n",
       "\n",
       "[154 rows x 4 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(154, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.loc[:12000,:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc(predictions,target):\n",
    "    '''\n",
    "    This methods returns the AUC Score when given the Predictions\n",
    "    and Labels\n",
    "    '''\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\daves\\OneDrive\\Desktop\\Sem 6\\Research\\GRU.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/daves/OneDrive/Desktop/Sem%206/Research/GRU.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m xtrain, xvalid, ytrain, yvalid \u001b[39m=\u001b[39m train_test_split(train\u001b[39m.\u001b[39;49mQuestions\u001b[39m.\u001b[39;49mvalues, train\u001b[39m.\u001b[39;49mBloomsTaxClass\u001b[39m.\u001b[39;49mvalues, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daves/OneDrive/Desktop/Sem%206/Research/GRU.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                                                   stratify\u001b[39m=\u001b[39;49mtrain\u001b[39m.\u001b[39;49mBloomsTaxClass\u001b[39m.\u001b[39;49mvalues, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daves/OneDrive/Desktop/Sem%206/Research/GRU.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                   random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/daves/OneDrive/Desktop/Sem%206/Research/GRU.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                   test_size\u001b[39m=\u001b[39;49m\u001b[39m0.3\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2445\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2441\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2443\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2445\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[0;32m   2447\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2448\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2449\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m )\n",
      "File \u001b[1;32mc:\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1604\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1574\u001b[0m \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1575\u001b[0m \n\u001b[0;32m   1576\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[39mto an integer.\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1603\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1604\u001b[0m \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1605\u001b[0m     \u001b[39myield\u001b[39;00m train, test\n",
      "File \u001b[1;32mc:\\python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1944\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1942\u001b[0m class_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   1943\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mmin(class_counts) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1944\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe least populated class in y has only 1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1946\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m member, which is too few. The minimum\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1947\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m number of groups for any class cannot\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1948\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m be less than 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1949\u001b[0m     )\n\u001b[0;32m   1951\u001b[0m \u001b[39mif\u001b[39;00m n_train \u001b[39m<\u001b[39m n_classes:\n\u001b[0;32m   1952\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1953\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe train_size = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m should be greater or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1954\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mequal to the number of classes = \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   1955\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "xtrain, xvalid, ytrain, yvalid = train_test_split(train.Questions.values, train.BloomsTaxClass.values, \n",
    "                                                  stratify=train.BloomsTaxClass.values, \n",
    "                                                  random_state=42, \n",
    "                                                  test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using keras tokenizer here\n",
    "token = text.Tokenizer(num_words=None)\n",
    "max_len = 1500\n",
    "\n",
    "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
    "xtrain_seq = token.texts_to_sequences(xtrain)\n",
    "xvalid_seq = token.texts_to_sequences(xvalid)\n",
    "\n",
    "#zero pad the sequences\n",
    "xtrain_pad =pad_sequences(xtrain_seq, maxlen=max_len)\n",
    "xvalid_pad =pad_sequences(xvalid_seq, maxlen=max_len)\n",
    "\n",
    "word_index = token.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the GloVe vectors in a dictionary:\n",
    "\n",
    "# embeddings_index = {}\n",
    "# f = open('glove.840B.300d.txt','r',encoding='utf-8')\n",
    "# for line in tqdm(f):\n",
    "#     values = line.split(' ')\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray([float(val) for val in values[1:]])\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close()\n",
    "\n",
    "# print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an embedding matrix for the words we have in the dataset\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    # GRU with glove embeddings and two dense layers\n",
    "     model = Sequential()\n",
    "     model.add(Embedding(len(word_index) + 1,\n",
    "                     300,\n",
    "                     weights=[embedding_matrix],\n",
    "                     input_length=max_len,\n",
    "                     trainable=False))\n",
    "     model.add(SpatialDropout1D(0.3))\n",
    "     model.add(GRU(300))\n",
    "     model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "     model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n",
    "    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(xtrain_pad, ytrain, nb_epoch=5, batch_size=64*strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.predict(xvalid_pad)\n",
    "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model.append({'Model': 'GRU','AUC_Score': roc_auc(scores,yvalid)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c19fa61d258bb2b35aae2ada233c33e2817c1ce895aa48acba720c6bf7cbe3cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
